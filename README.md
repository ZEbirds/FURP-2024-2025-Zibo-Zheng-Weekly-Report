# FURP-2024-2025-Zibo-Zheng-Weekly-Report
This week, I replicated the zoeDepth algorithm for estimating the depth of images, and then combined the original image pixels with the depth map to convert and visualize the 3D point cloud.
Code could be found in /code/zoemodel blog.py

Result as shown below and also could be found in /result:
![image](https://github.com/user-attachments/assets/cf192af0-bc61-4097-8753-04fc9dbcdcbb)
![image](https://github.com/user-attachments/assets/97c3cfdc-9ef2-41a8-85be-0f4641f0c79a)
![image](https://github.com/user-attachments/assets/f718c348-34ab-4a92-8199-78112bbf15c2)


# 3D Point Cloud Generation from Monocular Images ðŸš€
**FURP-2024-2025 | Weekly Report: Depth Estimation & 3D Reconstruction**  
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Open3D](https://img.shields.io/badge/Open3D-0.17.0-green)
![ZoeDepth](https://img.shields.io/badge/ZoeDepth-v1.0.0-orange)

<div align="center">
  <img src="https://github.com/user-attachments/assets/cf192af0-bc61-4097-8753-04fc9dbcdcbb" width="30%">
  <img src="https://github.com/user-attachments/assets/97c3cfdc-9ef2-41a8-85be-0f4641f0c79a" width="30%">
  <img src="https://github.com/user-attachments/assets/f718c348-34ab-4a92-8199-78112bbf15c2" width="30%">
</div>

## ðŸ” é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®å¤çŽ°äº†**ZoeDepthå•ç›®æ·±åº¦ä¼°è®¡ç®—æ³•**[1](@ref)ï¼Œå®žçŽ°äº†ä»ŽRGBå›¾åƒåˆ°3Dç‚¹äº‘çš„å®Œæ•´è½¬æ¢æµç¨‹ã€‚æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **æ·±åº¦å›¾ç”Ÿæˆ**ï¼šé‡‡ç”¨è½»é‡åŒ–ZoeDepth-Næ¨¡åž‹å®žçŽ°å®žæ—¶æ·±åº¦é¢„æµ‹
2. **ç‚¹äº‘è½¬æ¢**ï¼šç»“åˆOpen3Då°†åƒç´ åæ ‡æ˜ å°„åˆ°3Dç©ºé—´
3. **äº¤äº’å¯è§†åŒ–**ï¼šæ”¯æŒåŠ¨æ€æ—‹è½¬/ç¼©æ”¾çš„ç‚¹äº‘æŽ¢ç´¢ç•Œé¢

## âš™ï¸ æŠ€æœ¯å®žçŽ°
### ç®—æ³•æž¶æž„
```mermaid
graph LR
A[RGB Image] --> B(ZoeDepth Model)
B --> C[Depth Map]
C --> D(Point Cloud Conversion)
D --> E[Interactive 3D Visualization]
